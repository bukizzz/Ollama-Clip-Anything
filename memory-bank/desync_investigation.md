# A/V Desynchronization Investigation

## Objective
To identify the root cause of the audio-video desynchronization that occurs after the first scene change in the generated clips.

## Initial Findings

### `llm/llm_interaction.py`
- **Timestamp Generation:** Timestamps are generated by an LLM and validated by Pydantic models.
- **Validation:** The `Clip` and `Scene` models enforce chronological order and prevent overlaps. The `sanitize_segments` function adjusts clip durations, which could be a potential source of minor timing discrepancies.

### `video/clip_enhancer.py`
- **Scene Segmentation:** Uses a hybrid approach. Static scenes are extracted with `ffmpeg -ss ... -t ...`, which is generally accurate. Dynamic scenes are processed frame-by-frame with OpenCV, which should also be precise.
- **Concatenation:** Uses FFmpeg's `concat` demuxer, a standard and reliable method.
- **Audio Handling:** A single audio stream is extracted for the entire clip.

### `video/video_editing.py`
- **Parallel Processing:** Uses a `ThreadPoolExecutor` to process clips in parallel.
- **Data Flow:** Confirms that the LLM-generated timestamps are passed down to the clip creation function.

## Hypotheses
1.  **Audio/Video Duration Mismatch:** The total duration of the concatenated video segments may not perfectly match the duration of the separately extracted audio stream. This is the most likely cause of the desync.
2.  **Frame-Perfect Seeking:** Minor inaccuracies in OpenCV's `cv2.CAP_PROP_POS_MSEC` could accumulate over multiple scenes.
3.  **VFR vs. CFR:** Processing a variable frame rate video as if it were constant can introduce timing errors.

## Next Steps
- Formulate a detailed plan to address these hypotheses.
- Present the plan for review before implementing any changes.
